{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the CoreML Model with Image Input\n",
    "\n",
    "This notebook tests our converted CoreML model that takes an image as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import coremltools as ct\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "Load the CoreML model that was converted with image input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the CoreML model\n",
    "model_path = 'model.mlpackage'\n",
    "model = ct.models.MLModel(model_path)\n",
    "\n",
    "# Print model input and output descriptions\n",
    "print(\"Model inputs:\")\n",
    "print(model.input_description)\n",
    "print(\"\\nModel outputs:\")\n",
    "print(model.output_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Test Image\n",
    "\n",
    "Download a test image and resize it to 224x224 pixels to match the model input shape."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Download a sample image (a dog image from PyTorch's repo)\nimage_url = 'https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg'\nresponse = requests.get(image_url)\nimg = Image.open(BytesIO(response.content))\nprint(f\"Image format: {img.format}, size: {img.size}, mode: {img.mode}\")\n\n# Resize to match model input size (224x224)\nimg_resized = img.resize((224, 224))\n\n# Display the image\nplt.figure(figsize=(6, 6))\nplt.imshow(img_resized)\nplt.axis('off')\nplt.title('Test Image (Resized to 224x224)')\nplt.show()",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Run inference with the CoreML model using the test image."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Convert PIL image to proper format for CoreML\n# CoreML handles image preprocessing but requires the right format\n\n# Method 1: Direct PIL image input\ntry:\n    print(\"Trying prediction with direct PIL image...\")\n    prediction = model.predict({\"input\": img_resized})\n    print(\"Direct PIL image input worked!\")\nexcept Exception as e:\n    print(f\"Error with direct PIL image: {e}\")\n    \n    # Method 2: Try with PIL image converted to BGR numpy array\n    try:\n        print(\"\\nTrying with numpy array...\")\n        # Convert PIL image to numpy array (RGB)\n        img_array = np.array(img_resized)\n        # CoreML may expect BGR format\n        prediction = model.predict({\"input\": img_array})\n        print(\"Numpy array input worked!\")\n    except Exception as e:\n        print(f\"Error with numpy array: {e}\")\n        \n        # Method 3: Try with normalized array\n        try:\n            print(\"\\nTrying with normalized numpy array...\")\n            # Normalize the image to match preprocessing in the model conversion\n            img_array = np.array(img_resized).astype(np.float32)\n            # Reshape to match expected input (batch, channels, height, width)\n            img_array = np.transpose(img_array, (2, 0, 1))  # CHW format\n            img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n            prediction = model.predict({\"input\": img_array})\n            print(\"Normalized array input worked!\")\n        except Exception as e:\n            print(f\"Error with normalized array: {e}\")\n            prediction = None\n\n# Display the prediction results if we have a successful prediction\nif prediction:\n    print(\"\\nPrediction results:\")\n    for key, value in prediction.items():\n        print(f\"{key}:\")\n        if isinstance(value, np.ndarray):\n            print(f\"  Shape: {value.shape}\")\n            print(f\"  Max value: {value.max()}\")\n            print(f\"  Min value: {value.min()}\")\n            # If this is a classification model with probabilities, show top 5 classes\n            if len(value.shape) == 2 and value.shape[1] > 1:\n                top_indices = np.argsort(value[0])[::-1][:5]\n                print(\"  Top 5 classes:\")\n                for i, idx in enumerate(top_indices):\n                    print(f\"    {i+1}. Class {idx}: {value[0][idx]:.6f}\")\n        else:\n            print(f\"  {value}\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Features (Optional)\n",
    "\n",
    "If the model outputs feature vectors or activation maps, you can visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get the first output of the model (if it's an array of features or activations)\n",
    "output_key = list(prediction.keys())[0]\n",
    "output_data = prediction[output_key]\n",
    "\n",
    "# If the output is a feature vector, visualize top activations\n",
    "if isinstance(output_data, np.ndarray) and len(output_data.shape) == 2 and output_data.shape[1] > 1:\n",
    "    # Flatten and get top activations\n",
    "    flat_output = output_data[0]\n",
    "    top_indices = np.argsort(flat_output)[::-1][:20]  # Get top 20 activations\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(range(len(top_indices)), flat_output[top_indices])\n",
    "    plt.title(f'Top 20 Activations for {output_key}')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Activation Value')\n",
    "    plt.show()\n",
    "\n",
    "# Save the test image for future reference\n",
    "img_resized.save('test_image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We successfully tested the CoreML model that takes an image as input. The model processed the image correctly and produced predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}